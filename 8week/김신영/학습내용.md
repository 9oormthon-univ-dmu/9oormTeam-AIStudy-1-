## 8주차 - 차근차근 PyTorch & TorchVision - MLOps를 위한 모델 실험 추적 & 모델 웹앱 배포까지

## 8. Converting Source Code to Modules
### 강의 키워드
Converting Source Code, Argparse
### 강의내용

`utility`의 기능은 주로 반복적으로 사용되는 공통 작업이나 보조 기능을 수행하는 함수들을 모아 놓는 것입니다. 

특히, `train.py`에서 사용되는 `utility`는 모델을 저장하는 역할을 담당하고 있습니다.

구체적으로, 앞서 설명된 `utility` 함수의 기능을 살펴보면:

```python
def save_model(model, 
               target_dir,
               model_name):

    model_save_path = target_dir + '/' + model_name
    
    print("[INFO] Saving model to: {}".format(model_save_path))
    
    torch.save(obj=model.state_dict(),
               f=model_save_path)
```

### 기능 설명:
1. **`save_model` 함수**: 
   - **모델 저장**: 학습이 끝난 모델을 지정된 경로(`target_dir`)와 파일명(`model_name`)으로 저장합니다.
   - **상태 저장**: `model.state_dict()`를 사용해 모델의 가중치와 파라미터를 저장합니다.
   - **파일 경로 출력**: 저장 경로를 출력하여 사용자가 어디에 모델이 저장되었는지 알 수 있게 해줍니다.

### 주요 역할:
- 모델을 학습 후에 저장하고, 추후에 저장된 모델을 불러와 사용할 수 있도록 해줍니다.
- 파일 저장 위치를 명확하게 관리하여 모델 파일을 체계적으로 관리할 수 있도록 돕습니다.

즉, `utility`는 코드의 다른 부분에서 자주 사용될 수 있는 기능들을 효율적으로 관리하기 위한 보조 역할을 합니다.

---------------------------------------------
아래는 `train.py` 파일을 나중에 `argparse`와 함께 사용하는 방법을 설명한 마크다운 파일입니다. 이 파일은 사용자가 이후에 참고할 수 있도록 정리되어 있으며, 실시간으로 실행 결과를 확인하는 점을 강조합니다.

```markdown
# Converting Source Code to Modules and Using `argparse`

## 1. 파이썬 파일을 모듈화하여 저장

아래 코드는 `%%writefile` 명령어를 사용해 파이썬 파일로 저장됩니다. 이를 통해 코드 모듈화를 할 수 있습니다.

```python
%%writefile model_module/train.py

import os
import argparse

import torch
from torchvision import transforms
from torchmetrics import Accuracy

import prepare_data, train_funcs, build_model, utils

# Argparse for hyper-parameters
parser = argparse.ArgumentParser(description="Argparser for hyper-parameters")

parser.add_argument("--num_epochs", 
                     default=30, 
                     type=int, 
                     help="the number of epochs")

parser.add_argument("--batch_size",
                    default=32,
                    type=int,
                    help="number of samples per batch")

parser.add_argument("--num_filters",
                    default=32,
                    type=int,
                    help="number of filters to use in convolution layers")

parser.add_argument("--learning_rate",
                    default=0.001,
                    type=float,
                    help="learning-rate")

parser.add_argument("--train_dir",
                    default="data_food101/data/train",
                    type=str,
                    help="directory path of training data")

parser.add_argument("--test_dir",
                    default="data_food101/data/test",
                    type=str,
                    help="directory path of testing data")

args = parser.parse_args()

NUM_EPOCHS = args.num_epochs
BATCH_SIZE = args.batch_size
NUM_FILTERS = args.num_filters
LEARNING_RATE = args.learning_rate

print("[INFO] Setup - Epochs : {} | Batch_size : {} | Num_filters : {} | Learning_rate : {}".format(NUM_EPOCHS, 
                                                                                                    BATCH_SIZE, 
                                                                                                    NUM_FILTERS, 
                                                                                                    LEARNING_RATE))

train_dir = args.train_dir
test_dir = args.test_dir

print("[INFO] Training directory : {}".format(train_dir))
print("[INFO] Testing directory : {}".format(test_dir))

device = "cuda" if torch.cuda.is_available() else "cpu"

train_transform = transforms.Compose([
    transforms.Resize((64, 64)),
    transforms.TrivialAugmentWide(num_magnitude_bins=31), 
    transforms.ToTensor() 
])
test_transform = transforms.Compose([
    transforms.Resize((64, 64)),
    transforms.ToTensor()
])

train_dataloader, test_dataloader, class_names = prepare_data.create_dataloaders(
    train_dir=train_dir,
    test_dir=test_dir,
    train_transform=train_transform,
    test_transform=test_transform,
    batch_size=BATCH_SIZE
)

model = build_model.CNNAugment_TinyVGG(num_channels=3, 
                                       num_filters=NUM_FILTERS, 
                                       num_classes=len(class_names)).to(device)

loss_fn = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)                  
metric_accuracy = Accuracy().to(device)

train_funcs.train(model=model,
                  train_dataloader=train_dataloader,
                  test_dataloader=test_dataloader,
                  optimizer=optimizer,
                  loss_fn=loss_fn,
                  metric=metric_accuracy,
                  device=device,
                  epochs=NUM_EPOCHS)

utils.save_model(model=model,
                 target_dir="model_module/models",
                 model_name="CNNAugment_TinyVGG_modular.pth")
```

## 2. `argparse`를 통한 파라미터 설정 및 실행

이 코드에서는 `argparse`를 사용해 파라미터를 외부에서 쉽게 입력받아 모델의 학습을 설정할 수 있습니다. 예를 들어, `num_epochs`, `batch_size`, `num_filters`, `learning_rate` 등을 명령행에서 직접 설정 가능합니다.

### 실행 예시

```bash
!python model_module/train.py --num_epochs 1 --batch_size 32 --num_filters 32 --learning_rate 0.001
```

이 명령어를 사용하면, 각 파라미터에 맞춰 학습이 진행되며, `train.py` 파일에 설정된 대로 모델이 학습된 후 저장됩니다.

## 3. 실시간으로 학습 결과 확인하기

종료 시점에서만 결과를 확인하는 것이 아닌, 학습 도중 실시간으로 진행 상황을 확인하고 싶다면, 명령어를 직접 터미널이나 cmd 창에서 실행하는 것이 좋습니다. 이렇게 하면 학습 진행 상황을 10 epoch 이상 실시간으로 확인하며, 이후에 테스트와 이미지 예측 등의 후속 작업을 수행할 수 있습니다.

### 실행 명령어

```bash
python model_module/train.py --num_epochs 10 --batch_size 32 --num_filters 32 --learning_rate 0.001
```

이 명령어를 사용하여 학습 도중 실시간으로 출력되는 로그를 확인할 수 있으며, 이를 통해 모델의 성능 향상을 추적할 수 있습니다.

--------------------------------------------------------------------------------------------------------

## 9-1.Transfer-learning 1 - Introduction to torchvision.models
여러 torchvvision model들을 설명했고 이미 만들어진 모델들을 활용할 수 있는 것이 신기하였습니다.
보통 공부를 할 때 공식문서를 보라고 하는데 딥러닝은 어디서 봐야하는지 잘 몰랐는데 다양한 사이트와 다양한 모델들을 설명해주셔서 실제로 프로젝트를 할 때 참고하기에 좋아보였습니다. 
